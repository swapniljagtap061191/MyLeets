{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12fa052b-65ab-42fe-92e9-866a91ab0479",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e02171b5-8b8d-4b81-8826-2fb3ee1a8a24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.driver.memory\", \"10g\")\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"268435456\")\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Topics </h1>\n",
    "\n",
    "1. Reading Files (parquet)\n",
    "2. Narrow Operations\n",
    "   - `filter`\n",
    "   - `withColumn`: adding/modifying a column\n",
    "   - `select`: selecting relevant column\n",
    "3. Wide Operations\n",
    "   - Joins\n",
    "     - Sort Merge Join\n",
    "     - Broadcast Join\n",
    "   - GroupBy\n",
    "     - `count`\n",
    "     - `sum`\n",
    "     - `countDistinct`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_file = \"../data/data_skew/transactions.parquet\"\n",
    "df_transactions = spark.read.parquet(transactions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+-----------+\n",
      "|cust_id|txn_id|amt   |city       |\n",
      "+-------+------+------+-----------+\n",
      "|1      |1     |798.58|chicago    |\n",
      "|1      |2     |781.89|miami      |\n",
      "|1      |3     |164.46|chicago    |\n",
      "|1      |4     |108.98|chicago    |\n",
      "|1      |5     |867.51|los angeles|\n",
      "|1      |6     |151.44|chicago    |\n",
      "|1      |7     |30.38 |new york   |\n",
      "|1      |8     |724.78|seattle    |\n",
      "|1      |9     |220.22|los angeles|\n",
      "|1      |10    |191.57|los angeles|\n",
      "|1      |11    |615.54|miami      |\n",
      "|2      |12    |298.32|chicago    |\n",
      "|2      |13    |405.86|los angeles|\n",
      "|2      |14    |974.02|seattle    |\n",
      "|2      |15    |99.7  |seattle    |\n",
      "|2      |16    |207.68|los angeles|\n",
      "|2      |17    |596.49|chicago    |\n",
      "|2      |18    |861.34|miami      |\n",
      "|2      |19    |455.99|new york   |\n",
      "|2      |20    |949.4 |los angeles|\n",
      "|2      |21    |567.66|new york   |\n",
      "|2      |22    |311.57|miami      |\n",
      "|2      |23    |238.58|los angeles|\n",
      "|2      |24    |445.75|los angeles|\n",
      "|3      |25    |44.04 |seattle    |\n",
      "|3      |26    |397.15|new york   |\n",
      "|3      |27    |665.9 |new york   |\n",
      "|3      |28    |430.9 |seattle    |\n",
      "|3      |29    |551.24|seattle    |\n",
      "|3      |30    |41.0  |new york   |\n",
      "|3      |31    |777.38|new york   |\n",
      "|3      |32    |401.2 |los angeles|\n",
      "|3      |33    |601.92|seattle    |\n",
      "|3      |34    |204.02|boston     |\n",
      "|3      |35    |961.56|miami      |\n",
      "|3      |36    |394.79|new york   |\n",
      "|4      |37    |590.88|boston     |\n",
      "|4      |38    |288.13|los angeles|\n",
      "|4      |39    |283.24|miami      |\n",
      "|4      |40    |804.18|boston     |\n",
      "|4      |41    |25.48 |boston     |\n",
      "|4      |42    |774.52|los angeles|\n",
      "|4      |43    |300.55|chicago    |\n",
      "|4      |44    |206.85|chicago    |\n",
      "|4      |45    |792.27|chicago    |\n",
      "|5      |46    |927.04|new york   |\n",
      "|5      |47    |124.71|boston     |\n",
      "|5      |48    |627.07|new york   |\n",
      "|5      |49    |104.46|seattle    |\n",
      "|5      |50    |331.93|chicago    |\n",
      "+-------+------+------+-----------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transactions.show(50, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A `batch` refers to a group of rows that are processed together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_file = \"../data/data_skew/customers.parquet\"\n",
    "df_customers = spark.read.parquet(customers_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+-----------+---+------+----------+\n",
      "|cust_id|name          |city       |age|gender|birthday  |\n",
      "+-------+--------------+-----------+---+------+----------+\n",
      "|1      |John Doe      |miami      |21 |F     |1968-10-03|\n",
      "|2      |Jane Smith    |boston     |33 |M     |1949-10-18|\n",
      "|3      |Bob Johnson   |new york   |23 |F     |1988-02-24|\n",
      "|4      |Alice Brown   |los angeles|50 |M     |1957-07-02|\n",
      "|5      |Charlie Wilson|boston     |56 |M     |1964-01-06|\n",
      "+-------+--------------+-----------+---+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_customers.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Narrow Transformations\n",
    "- `filter` rows where `city='boston'`\n",
    "- `add` a new column: adding `first_name` and `last_name`\n",
    "- `alter` an exisitng column: adding 5 to `age` column\n",
    "- `select` relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_narrow_transform = (\n",
    "    df_customers\n",
    "    .filter(F.col(\"city\") == \"boston\")\n",
    "    .withColumn(\"first_name\", F.split(\"name\", \" \").getItem(0))\n",
    "    .withColumn(\"last_name\", F.split(\"name\", \" \").getItem(1))\n",
    "    .withColumn(\"age\", F.col(\"age\") + F.lit(5))\n",
    "    .select(\"cust_id\", \"first_name\", \"last_name\", \"age\", \"gender\", \"birthday\")\n",
    ")\n",
    "\n",
    "df_narrow_transform.write.format(\"noop\").mode(\"overwrite\").save(\"../data/test/df_narrow_transform.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+---+------+----------+\n",
      "|cust_id|first_name|last_name|age|gender|birthday  |\n",
      "+-------+----------+---------+---+------+----------+\n",
      "|2      |Jane      |Smith    |38 |M     |1949-10-18|\n",
      "|5      |Charlie   |Wilson   |61 |M     |1964-01-06|\n",
      "|6      |Diana     |Davis    |80 |M     |1956-09-01|\n",
      "|21     |Steve     |King     |78 |M     |1955-08-05|\n",
      "|24     |Victoria  |Hill     |81 |M     |1968-10-16|\n",
      "|38     |Jasmine   |Taylor   |46 |F     |1959-07-01|\n",
      "|54     |Alice     |Brown    |45 |M     |1987-05-27|\n",
      "+-------+----------+---------+---+------+----------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_narrow_transform.show(7, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_gt_50 = (\n",
    "    df_customers\n",
    "    .filter(F.col(\"age\").cast(\"int\") > 50)\n",
    ")\n",
    "df_customer_gt_50.write.format(\"noop\").mode(\"overwrite\").save(\"../data/test/df_customer_gt_50.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide Transformations\n",
    "1. Joins\n",
    "   - Sort Merge Join\n",
    "   - Broadcast Join\n",
    "2. GroupBy\n",
    "   - `count`\n",
    "   - `countDistinct`\n",
    "   - `sum`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort Merge Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = (\n",
    "    df_transactions.join(\n",
    "        df_customers,\n",
    "        how=\"inner\",\n",
    "        on=\"cust_id\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.write.format(\"noop\").mode(\"overwrite\").save(\"../data/test/df_joined.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcast Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 10485760)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_broadcast_joined = (\n",
    "    df_transactions.join(\n",
    "        F.broadcast(df_customers),\n",
    "        how=\"inner\",\n",
    "        on=\"cust_id\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_broadcast_joined.write.format(\"noop\").mode(\"overwrite\").save(\"../data/test/df_broadcast_joined.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GroupBy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city_counts = (\n",
    "    df_transactions\n",
    "    .groupBy(\"city\")\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|city    |count|\n",
      "+--------+-----+\n",
      "|new york|157  |\n",
      "|chicago |146  |\n",
      "|boston  |174  |\n",
      "|seattle |183  |\n",
      "|miami   |190  |\n",
      "+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_city_counts.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txn_amt_city = (\n",
    "    df_transactions\n",
    "    .groupBy(\"city\")\n",
    "    .agg(F.sum(\"amt\").alias(\"txn_amt\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|city    |txn_amt          |\n",
      "+--------+-----------------+\n",
      "|new york|83904.73000000007|\n",
      "|chicago |67404.06000000003|\n",
      "|boston  |77801.67000000004|\n",
      "|seattle |93322.53999999998|\n",
      "|miami   |96800.70999999996|\n",
      "+--------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_txn_amt_city.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy Count Distinct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txn_per_city = (\n",
    "    df_transactions\n",
    "    .groupBy(\"city\")\n",
    "    .agg(F.countDistinct(\"txn_id\").alias(\"txn_count\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|city    |txn_count|\n",
      "+--------+---------+\n",
      "|new york|157      |\n",
      "|chicago |146      |\n",
      "|boston  |174      |\n",
      "|seattle |183      |\n",
      "|miami   |190      |\n",
      "+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_txn_per_city.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data-skew-explanation",
   "notebookOrigID": 4018749166498458,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
